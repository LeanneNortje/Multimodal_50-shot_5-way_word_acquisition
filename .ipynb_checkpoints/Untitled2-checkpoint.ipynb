{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638d7415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leannenortje/anaconda3/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/leannenortje/anaconda3/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK2at10TensorBase21__dispatch_contiguousEN3c1012MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# from dataloaders import *\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import apex\n",
    "from apex import amp\n",
    "import time\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628c9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = [\n",
    "        'air', \n",
    "        'baby',\n",
    "        'ball',\n",
    "        'beach',\n",
    "        'bike',\n",
    "        'boy',\n",
    "        'building',\n",
    "        'car',\n",
    "        'children',\n",
    "        'dirt',\n",
    "        'dogs',\n",
    "        'face',\n",
    "        'field',\n",
    "        'football',\n",
    "        'grass',\n",
    "        'hair',\n",
    "        'mountain',\n",
    "        'mouth',\n",
    "        'ocean',\n",
    "        'park',\n",
    "        'pool',\n",
    "        'road',\n",
    "        'rock',\n",
    "        'sand',\n",
    "        'skateboard',\n",
    "        'smiling',\n",
    "        'snow',\n",
    "        'snowy',\n",
    "        'soccer',\n",
    "        'street',\n",
    "        'toy',\n",
    "        'tree',\n",
    "        'water',\n",
    "        'women'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447d4d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e22959",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/flickr8k.pickle', \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "samples = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bd1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base = Path('/mnt/HDD/leanne_HDD/Datasets/Flicker8k_Dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b7adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_image = {}\n",
    "for entry in samples:\n",
    "    im_fn = image_base / Path('_'.join(str(Path(entry['wave']).stem).split('_')[0:2])  + '.jpg')\n",
    "    gt_trn = [i for i in entry[\"trn\"] if i in VOCAB]\n",
    "    for word in gt_trn:\n",
    "        if word not in word_to_image: word_to_image[word] = []\n",
    "        if len(word_to_image[word]) < 10: word_to_image[word].append((im_fn, str(Path(entry['wave']).stem)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0ae059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boy: 10\n",
      "beach: 10\n",
      "snow: 10\n",
      "rock: 10\n",
      "face: 10\n",
      "tree: 10\n",
      "football: 10\n",
      "dogs: 10\n",
      "women: 10\n",
      "water: 10\n",
      "children: 10\n",
      "hair: 10\n",
      "mountain: 10\n",
      "building: 10\n",
      "grass: 10\n",
      "ball: 10\n",
      "bike: 10\n",
      "soccer: 10\n",
      "field: 10\n",
      "street: 10\n",
      "baby: 10\n",
      "dirt: 10\n",
      "pool: 10\n",
      "ocean: 10\n",
      "park: 10\n",
      "road: 10\n",
      "smiling: 10\n",
      "sand: 10\n",
      "air: 10\n",
      "toy: 10\n",
      "car: 10\n",
      "mouth: 10\n",
      "skateboard: 10\n",
      "snowy: 10\n"
     ]
    }
   ],
   "source": [
    "for w in word_to_image:\n",
    "    print(f'{w}: {len(word_to_image[w])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa26bfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c8c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    Path('data/words_to_images_for_det_and_loc'),\n",
    "    word_images=word_to_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ada9dde7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2881\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2882\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2883\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-07e7b9167f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_to_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstrained_layout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2882\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2884\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2885\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'read'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word in word_to_image:\n",
    "    fig = plt.figure(figsize=(50, 50), constrained_layout=True)\n",
    "    plt.imshow(Image.open(word_to_image[word][0][0]).convert('RGB'))\n",
    "    plt.axis('off')\n",
    "    plt.title(word, fontsize=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76797fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterEnv",
   "language": "python",
   "name": "jupyterenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
